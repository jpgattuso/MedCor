---
title: "Light MedCor"
author: "Jean-Pierre Gattuso, CNRS-Sorbonne University (jean-pierre.gattuso@imev-mer.fr)"
date: '`r format(Sys.Date(), "%d %B %Y")`'
output:
  html_document:
  code_folding: hide
fig_caption: yes
toc: no
toc_float: no
pdf_document:
  toc: no
---
  
```{r setup, include=FALSE}
rm(list = ls())
knitr::opts_chunk$set(echo = TRUE)
if (!require("tidyverse")) install.packages("tidyverse")
library("tidyverse")
if (!require("readxl")) install.packages("readxl")
library("readxl")
if (!require("writexl")) install.packages("writexl")
library("writexl")
if (!require("FNN")) install.packages("FNN")
library("FNN") # For fastest nearest neighbour searching
if (!require("devtools")) install.packages("devtools")
library(devtools)
if (!require("CoastalLight")) install_github("jpgattuso/CoastalLight")
library(CoastalLight)
if (!require("lubridate")) install.package("lubridate")
library(lubridate)

# function to transform coordinates
dms2dec <- function(dms, separators = c("º", "°", "\'", "’", "’’", "\"", "\'\'", "\\?")) {
  
  # by A. Marcia Barbosa (https://modtools.wordpress.com/)
  # license: CC BY-SA 4.0 (Creative Commons)
  # like R, this function is free, open-source and comes with absolutely no warranty; bug reports welcome!
  
  # version 1.4 (2 Feb 2022)
  # dms: a vector of latitude or longitude in degrees-minutes-seconds-hemisfere, e.g. 41° 34' 10.956" N (with or without spaces)
  # separators: the characters that are separating degrees, minutes and seconds in dms
  
  # to source this function, remember to add encoding: source("https://raw.githubusercontent.com/AMBarbosa/unpackaged/master/dms2dec", encoding = "UTF-8")
  dms <- as.character(dms)
  dms <- gsub(pattern = " ", replacement = "", x = dms)
  for (s in separators) dms <- gsub(pattern = s, replacement = "_splitHere_", x = dms)
  
  splits <- strsplit(dms, split = "_splitHere_")
  n <- length(dms)
  deg <- min <- sec <- hem <- vector("character", n)
  
  for (i in 1:n) {
    deg[i] <- splits[[i]][1]
    min[i] <- splits[[i]][2]
    
    if (length(splits[[i]]) < 4) {
      hem[i] <- splits[[i]][3]
    } else {
      sec[i] <- splits[[i]][3]
      hem[i] <- splits[[i]][4]
    }
  }
  
  dec <- colSums(rbind(as.numeric(deg), (as.numeric(min) / 60), (as.numeric(sec) / 3600)), na.rm = TRUE)
  sign <- ifelse (hem %in% c("N", "E"), 1, -1)
  hem_miss <- which(is.na(hem))
  if (length(hem_miss) > 0) {
    warning("Hemisphere not specified in position(s) ", hem_miss, ", so the sign of the resulting coordinates may be wrong.")
  }
  dec <- sign * dec
  return(dec)
}  # end dms2dec function
```

## Introduction

The goal is to add annual PAR as well as minimum and maximum monthy PAR to the data compilation built on Camp et al. (2018)


## Method

I have corrected dozens of mistakes in the geographical coordinates (extra space, wrong quotes). The excel sheet found in the drive is now machine-readable. ** There are many typos that remain to be corrected (Grotolli, Mediterranian...)

This script uses the R package CoastalLight described in the following paper:

Gattuso J.-P., Gentili B., Antoine D. & Doxaran D., 2020. Global distribution of photosynthetically available radiation on the seafloor. Earth System Science Data 12:1697-1709. http://dx.doi.org/10.5194/essd-12-1697-2020

The goal is to get PAR at specific locations. It can be done anywhere in the global ocean as the data products are global (and open access). A square was defined around each study location: +- 0.015 decimal degree latitude and +-0.015 decimal degree longitude, with the study location in the middle.  I get the data of about 20-50 cells (squares of ca 450 m on each side). Depth is in (negative) meter and bottom PAR in mol/m2/day. 

**Beware** that the script is slow when it is first run because two big files need to be downloaded from Pangaea. It will subsequently run faster (but not lighting fast!). **Be patient!**

**Important note :**
  Some sites have been skipped (NAs) because no GEBCO coastal (<200 m) cell was found in the square defined above

## Results

The file names of the output are "par.csv" and "par.xlsx". This script adds the following variables to the tab "GPS Coordinates":

* mean_depth: mean depth (m) of the cells comprised in the square defined above
* mean_area: mean area (km2) of the cells comprised in the square defined above
* par: mean atmospheric PAR in mol/(m2 d); it is the mean of the n mean values of bottom PAR of each grid cell (21 years × 12 months = 252 values)
* mean_kdpar: mean attenuation coefficient in m-1; it is the mean of the n mean values of kdpar of each grid cell (21 years × 12 months = 252 values)
* n: number of grid cells comprised in the square
* parbottom: mean bottom PAR in mol/(m2 d); it is the mean of the n mean value of bottom PAR of each grid cell (21 years × 12 months = 252 values)
* parbottom10: PAR at 10 m depth in mol/(m2 d) calculated as parbottom10 = par * exp(kdpar * 10).
* min_parbottom10: minimum monthly PAR at 10 m depth in mol/(m2 d) calculated as min_parbottom10 = par * exp(-kdpar * 10)
* max_parbottom10: maximum monthly PAR at 10 m depth in mol/(m2 d) calculated as min_parbottom10 = par * exp(-kdpar * 10)

```{r read Camp data, echo=FALSE, message=FALSE, warning=FALSE, include = TRUE}
# https://buckeyemailosu-my.sharepoint.com/personal/grottoli_1_osu_edu/_layouts/15/onedrive.aspx?id=%2Fpersonal%2Fgrottoli%5F1%5Fosu%5Fedu%2FDocuments%2FGrottoli%20data%2FGrottoli%20Lab%20DATA%2FMediterranean%20corals%2FMed%20coral%20reef%20review
geo <- readxl::read_excel(path = "data/Camp et al 2018 Abiotic Literature Search_Annotated_Grottoli v2.xlsx", sheet = "GPS Coordinates")
geo <- geo %>% 
  dplyr::mutate(id = seq(1:nrow(geo)),
                lat = dms2dec(latitude),
                lon = dms2dec(longitude)
  ) %>% 
  dplyr::select(id, everything()) #%>% 
  #dplyr::slice_head(n = 2)
```

```{r read PAR data, echo=FALSE, message=FALSE, warning=FALSE, include = TRUE}
if(!dir.exists("data/CoastalLight.d")){
  for (month in 0:12) {
    cl_DownloadData(month = month, dirdata = "data/CoastalLight.d")
  }
}
```

```{r annual PAR, echo=FALSE, message=FALSE, warning=FALSE, include = TRUE}
light_annual <-  NULL
i <- 0
for (j in 1:nrow(geo)) {
#for (j in 1:10) {
  i <- i + 1
  #print(i)
  print(paste0("Entry: ", j))
  z <- cl_GetData(dirdata = "data/CoastalLight.d",
                  lon=c(geo$lon[i]-0.015, geo$lon[i]+0.015), 
                  lat=c(geo$lat[i]-0.015, geo$lat[i]+0.015), month = 0)
  d <- dplyr::as_tibble(z$data) %>%
    dplyr::select(depth, area, par, kdpar, parbottom) %>%
    dplyr::mutate(depth = -depth)
  d_one <- d %>% # one line summary for this location
    dplyr::summarise_all(mean) %>%
    dplyr::mutate(
      n = nrow(d),
      parbottom10 = par * exp(-kdpar * 10)
    )
  light_annual <- dplyr::bind_rows(light_annual, d_one)
}
light_annual <- light_annual %>% 
    dplyr::rename(mean_depth = depth, mean_area = area, mean_par = par, 
                  mean_kdpar = kdpar, mean_parbottom = parbottom)
geo2 <- cbind(geo, light_annual) 
write_csv(x = geo2, file = "data/geo2.csv")
writexl::write_xlsx(x = geo2, path = "data/geo2.xlsx")
```

```{r monthly PAR, echo=FALSE, message=FALSE, warning=FALSE, include = TRUE}
geo2 <- read_csv(file = "data/geo2.csv")
  i <- 0
light_month <-  NULL
  for (j in 1:nrow(geo)) {
    for (m in 1:12) {
  i <- i + 1
  print(paste("id =", j, " - month =", m, sep = " "))
  z <- cl_GetData(dirdata = "data/CoastalLight.d",
                  lon=c(geo$lon[j]-0.015, geo$lon[j]+0.015), 
                  lat=c(geo$lat[j]-0.015, geo$lat[j]+0.015), 
                  month = m)
  d <- dplyr::as_tibble(z$data) %>%
    dplyr::select(depth, area, par, kdpar, parbottom) %>%
    dplyr::mutate(depth = -depth)
  d_one <- d %>% # one line summary for this location
    dplyr::summarise_all(mean) %>%
    dplyr::mutate(
      id = geo$id[j],
      month = m,
      n = nrow(d),
      parbottom10 = par * exp(-kdpar * 10)
    )
  light_month <- dplyr::bind_rows(light_month, d_one)
  light_month <- light_month %>% 
    dplyr::select(id, month, everything())
  }
}
write_csv(x = light_month, file = "data/light_month.csv")
writexl::write_xlsx(x = light_month, path = "data/light_month.xlsx")
light_by_id_month <- light_month %>% 
  dplyr::group_by(id) %>% 
  dplyr::summarise(min_parbottom10 = min(parbottom10),
                   max_parbottom10 = max(parbottom10)
  )
par <- dplyr::full_join(geo2, light_by_id_month, by = "id")
# save
write_csv(x = par, file = "data/par.csv")
writexl::write_xlsx(x = par, path = "data/par.xlsx")
```

```{r read MUR data, echo=FALSE, message=FALSE, warning=FALSE, results='hide'}
# GHRSST Level 4 MUR Global Foundation Sea Surface Temperature Analysis  
# [https://podaac-opendap.jpl.nasa.gov/opendap/hyrax/allData/ghrsst/data/GDS2/L4/GLOB/JPL/MUR/v4.1/README](https://podaac-opendap.jpl.nasa.gov/opendap/hyrax/allData/ghrsst/data/GDS2/L4/GLOB/JPL/MUR/v4.1/README)
# The time series starts in 2002 but we have used just 2016-2020 and extracted data for 20 of the 431 study sites. For each site, I have calculated the annual mean temperature from the daily measurements, and the minimum and maximum mean monthly means.

load("data/MUR_data.Rdata")
mur <- tibble(MUR_data)
annual_temp <- mur %>% 
  group_by(idx) %>% 
  summarise(annual_mean_temp = mean(temp)) %>% 
  ungroup() 
min_max_temp <- mur %>% 
  group_by(idx, month(t)) %>% 
  summarise(mean_monthly_temp = mean(temp)) %>% 
  group_by(idx) %>% 
  summarise(min_monthly_temp = min(mean_monthly_temp),
            max_monthly_temp = max(mean_monthly_temp)) %>% 
  ungroup() 
```
```{r merged data, echo=FALSE, message=FALSE, warning=FALSE, results='hide'}
temp <- full_join(annual_temp,  min_max_temp, by = "idx") %>% 
  dplyr::rename(id = idx)
par_temp <- full_join(par,  temp, by = "id")
write_csv(x = par_temp, file = "data/par_temp.csv")
writexl::write_xlsx(x = par_temp, path = "data/par_temp")
```